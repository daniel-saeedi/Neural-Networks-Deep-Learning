{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYfF_JqyTnX9"
   },
   "source": [
    "# Part A: Extracting 150 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkRVDvtmTaa7"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "vidcap = cv2.VideoCapture('DragonBall.mkv')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "frame_count = 0\n",
    "while success:\n",
    "    if count%200 == 0:\n",
    "        if frame_count <= 90:\n",
    "            cv2.imwrite(\"frames/train/frame%d.jpg\" % frame_count, image)     # save frame as JPEG file\n",
    "        else:\n",
    "            cv2.imwrite(\"frames/test/frame%d.jpg\" % frame_count, image)     # save frame as JPEG file\n",
    "        frame_count += 1\n",
    "    success,image = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "    if frame_count >= 121:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QOI1ydcsU7CL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import PIL\n",
    "# Ground Truth\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for i in range(0,90):\n",
    "  I = np.asarray(PIL.Image.open('frames/train/frame'+str(i)+'.jpg'))\n",
    "  train.append(I)\n",
    "for i in range(91,121):\n",
    "  I = np.asarray(PIL.Image.open('frames/test/frame'+str(i)+'.jpg'))\n",
    "  test.append(I)\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ela40S_XUlQG"
   },
   "source": [
    "# Part B: Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "vZcF3FFLXu3g"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train_lineart = []\n",
    "test_lineart = []\n",
    "\n",
    "for i in range(0,90):\n",
    "  I = cv.imread('frames/train/frame'+str(i)+'.jpg')\n",
    "  edges = cv.Canny(I,100,200)\n",
    "  train_lineart.append(edges)\n",
    "\n",
    "for i in range(91,121):\n",
    "  I = cv.imread('frames/train/frame'+str(i)+'.jpg')\n",
    "  edges = cv.Canny(I,100,200)\n",
    "  test_lineart.append(edges)\n",
    "\n",
    "train_lineart = np.array(train_lineart)\n",
    "test_lineart = np.array(test_lineart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, exists\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from skimage import io, feature, color, img_as_uint, util\n",
    "from skimage.transform import resize\n",
    "\n",
    "class DatasetFromFolder(data.Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        super(DatasetFromFolder, self).__init__()\n",
    "        self.photo_path = image_dir\n",
    "        self.image_filenames = [x for x in listdir(self.photo_path) if is_image_file(x)]\n",
    "        transform_list = [transforms.ToTensor()]\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load Image\n",
    "        try:\n",
    "            target_path = join(self.photo_path, self.image_filenames[index])\n",
    "            frame_num = target_path.split(\"e\")[-1]\n",
    "            frame_num = int(frame_num.split(\".\")[0]) - 1\n",
    "            #will be either black or colored\n",
    "            frame_prev = self.get_prev(frame_num) \n",
    "            target = load_img(target_path)\n",
    "            input = color.rgb2gray(target)\n",
    "            #Lineart\n",
    "            input = feature.canny(input,sigma = 1)\n",
    "            input = util.invert(input)\n",
    "            input = Image.fromarray(np.uint8(input)*255)\n",
    "            \n",
    "            input = Image.fromarray(input)\n",
    "            frame_prev = self.transform(frame_prev)\n",
    "            target = self.transform(target)\n",
    "            input = self.transform(input)\n",
    "\n",
    "            return input, target, frame_prev\n",
    "        except:\n",
    "            print(\"Something went wrong frame:\" + str(frame_num))\n",
    "            return self[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def get_prev(self, num):\n",
    "        if not exists(join(self.photo_path,\"frame\"+str(num)+\".jpg\")):\n",
    "            initial_prev_frame = Image.new(\"RGB\",[256,256])\n",
    "            return initial_prev_frame\n",
    "        else:\n",
    "            #define rnd num generator and if statement <0.5 take black or color\n",
    "            rnd = np.random.uniform(0,1)\n",
    "            if rnd <= 0.5:\n",
    "                prev = load_img(join(self.photo_path,\"frame\"+str(num)+\".jpg\"))\n",
    "            else:\n",
    "                prev = Image.new(\"RGB\",[256,256])\n",
    "\n",
    "            return prev\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_training_set(root_dir):\n",
    "    train_dir = join(root_dir, \"Train\")\n",
    "\n",
    "    return DatasetFromFolder(train_dir)\n",
    "\n",
    "\n",
    "def get_test_set(root_dir):\n",
    "    test_dir = join(root_dir, \"Test\")\n",
    "\n",
    "    return DatasetFromFolder(test_dir)\n",
    "\n",
    "def get_val_set(root_dir):\n",
    "    val_dir = join(root_dir, \"Val\")\n",
    "\n",
    "    return DatasetFromFolder(val_dir)\n",
    "\n",
    "def create_iterator(sample_size, sample_dataset):\n",
    "    while True:\n",
    "        sample_loader = DataLoader(\n",
    "            dataset= sample_dataset,\n",
    "            batch_size=sample_size,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        for item in sample_loader:\n",
    "            yield item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class AdversarialLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, type='nsgan', target_real_label=1.0, target_fake_label=0.0):\n",
    "        super(AdversarialLoss, self).__init__()\n",
    "\n",
    "        self.type = type\n",
    "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
    "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
    "\n",
    "        if type == 'nsgan':\n",
    "            self.criterion = nn.BCELoss() \n",
    "    \n",
    "\n",
    "        elif type == 'lsgan':\n",
    "            self.criterion = nn.MSELoss()\n",
    "\n",
    "        elif type == 'hinge':\n",
    "            self.criterion = nn.ReLU()\n",
    "\n",
    "    def __call__(self, outputs, is_real, is_disc=None):\n",
    "        if self.type == 'hinge':\n",
    "            if is_disc:\n",
    "                if is_real:\n",
    "                    outputs = -outputs\n",
    "                return self.criterion(1 + outputs).mean()\n",
    "            else:\n",
    "                return (-outputs).mean()\n",
    "\n",
    "        else:\n",
    "            labels = (self.real_label if is_real else self.fake_label).expand_as(outputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            return loss\n",
    "\n",
    "\n",
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StyleLoss, self).__init__()\n",
    "        self.add_module('vgg', VGG19())\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "\n",
    "    def compute_gram(self, x):\n",
    "        b, ch, h, w = x.size()\n",
    "        f = x.view(b, ch, w * h)\n",
    "        f_T = f.transpose(1, 2)\n",
    "        G = f.bmm(f_T) / (h * w * ch)\n",
    "\n",
    "        return G\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        # Compute features\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "\n",
    "        # Compute loss\n",
    "        style_loss = 0.0\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu2_2']), self.compute_gram(y_vgg['relu2_2']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu3_4']), self.compute_gram(y_vgg['relu3_4']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu4_4']), self.compute_gram(y_vgg['relu4_4']))\n",
    "        style_loss += self.criterion(self.compute_gram(x_vgg['relu5_2']), self.compute_gram(y_vgg['relu5_2']))\n",
    "\n",
    "        return style_loss\n",
    "\n",
    "\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, weights=[1.0, 1.0, 1.0, 1.0, 1.0]):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        self.add_module('vgg', VGG19())\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "        self.weights = weights\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "\n",
    "        content_loss = 0.0\n",
    "        content_loss += self.weights[0] * self.criterion(x_vgg['relu1_1'], y_vgg['relu1_1'])\n",
    "        content_loss += self.weights[1] * self.criterion(x_vgg['relu2_1'], y_vgg['relu2_1'])\n",
    "        content_loss += self.weights[2] * self.criterion(x_vgg['relu3_1'], y_vgg['relu3_1'])\n",
    "        content_loss += self.weights[3] * self.criterion(x_vgg['relu4_1'], y_vgg['relu4_1'])\n",
    "        content_loss += self.weights[4] * self.criterion(x_vgg['relu5_1'], y_vgg['relu5_1'])\n",
    "\n",
    "\n",
    "        return content_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(iteration):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        input,target,prev_frame = next(sample_iterator)\n",
    "        \n",
    "        if opt.cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            prev_frame = prev_frame.cuda()\n",
    "\n",
    "        pred_input = torch.cat((input,prev_frame),1)\n",
    "        prediction = netG(pred_input)\n",
    "        prediction = postprocess(prediction)\n",
    "        input = postprocess(input)\n",
    "        target = postprocess(target)\n",
    "\n",
    "    img = stitch_images(input, target, prediction)\n",
    "    samples_dir = root_path + \"/samples\"\n",
    "\n",
    "    if not os.path.exists(samples_dir):\n",
    "        os.makedirs(samples_dir)\n",
    "\n",
    "    sample = opt.dataset + \"_\" + str(epoch) + \"_\" + str(iteration).zfill(5) + \".png\"\n",
    "    print('\\nsaving sample ' + sample + ' - learning rate: ' + str(opt.lr))\n",
    "    img.save(os.path.join(samples_dir, sample))\n",
    "\n",
    "def log_train_data(loginfo):\n",
    "    log_dir = root_path + \"/logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    log_file = log_dir + \"/\" + opt.logfile\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write('%s\\n' % ' '.join([str(item[1]) for item in loginfo]))\n",
    "\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    if not os.path.exists(\"checkpoint\"):\n",
    "        os.mkdir(\"checkpoint\")\n",
    "    if not os.path.exists(os.path.join(\"checkpoint\", opt.dataset)):\n",
    "        os.mkdir(os.path.join(\"checkpoint\", opt.dataset))\n",
    "    net_g_model_out_path = \"checkpoint/{}/netG_weights_epoch_{}.pth\".format(opt.dataset, epoch)\n",
    "    net_d_model_out_path = \"checkpoint/{}/netD_weights_epoch_{}.pth\".format(opt.dataset, epoch)\n",
    "    \n",
    "    torch.save({'generator': netG.state_dict()}, net_g_model_out_path)\n",
    "    torch.save({'discriminator': netD.state_dict()}, net_d_model_out_path)\n",
    "    \n",
    "    print(\"Checkpoint saved to {}\".format(\"checkpoint\" + opt.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'root': './',\n",
    "    'dataset': 'frames/',\n",
    "    'logfile': True,\n",
    "    'checkpoint_path_G':True,\n",
    "    'checkpoint_path_D':True,\n",
    "    'batchSize':16,\n",
    "    'testBatchSize':1,\n",
    "    'nEpochs':100,\n",
    "    'input_nc':1,\n",
    "    'output_nc':3,\n",
    "    'lr':0.0001,\n",
    "    'beta1':0,\n",
    "    'cuda':'store_true',\n",
    "    'threads':0,\n",
    "    'seed':123,\n",
    "    'L1lamb':10,\n",
    "    'Stylelamb':1000,\n",
    "    'Contentlamb':1,\n",
    "    'Adversariallamb':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "from math import log10\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if opt.cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "\n",
    "print('===> Loading datasets')\n",
    "root_path = opt.root\n",
    "train_set = get_training_set(join(root_path , opt.dataset))\n",
    "test_set = get_test_set(join(root_path , opt.dataset))\n",
    "\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n",
    "\n",
    "sample_iterator = create_iterator(6, test_set)\n",
    "\n",
    "print('===> Building model')\n",
    "netG = define_G(opt.input_nc, opt.output_nc, opt.ngf, False, [0])\n",
    "netD = define_D(opt.input_nc + opt.output_nc, opt.ndf, False, [0])\n",
    "\n",
    "if opt.checkpoint_path_G and opt.checkpoint_path_D:\n",
    "    load(opt.checkpoint_path_G, opt.checkpoint_path_D, netG, netD)\n",
    "\n",
    "criterionGAN = AdversarialLoss()\n",
    "criterionSTYLE = StyleLoss()\n",
    "criterionCONTENT = PerceptualLoss()\n",
    "criterionL1 = nn.L1Loss()\n",
    "criterionMSE = nn.MSELoss()\n",
    "\n",
    "# setup optimizer\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr * 0.1, betas=(opt.beta1, 0.999))\n",
    "\n",
    "print('---------- Networks initialized -------------')\n",
    "print_network(netG)\n",
    "print_network(netD)\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "real_a = torch.FloatTensor(opt.batchSize, opt.input_nc, 256, 256)\n",
    "real_b = torch.FloatTensor(opt.batchSize, opt.output_nc, 256, 256)\n",
    "prev_b = torch.FloatTensor(opt.batchSize, opt.output_nc, 256, 256)\n",
    "\n",
    "if opt.cuda:\n",
    "    netD = netD.cuda()\n",
    "    netG = netG.cuda()\n",
    "    criterionGAN = criterionGAN.cuda()\n",
    "    criterionL1 = criterionL1.cuda()\n",
    "    critertionSTYLE = criterionSTYLE.cuda()\n",
    "    criterionCONTENT = criterionCONTENT.cuda()\n",
    "    criterionMSE = criterionMSE.cuda()\n",
    "    real_a = real_a.cuda()\n",
    "    real_b = real_b.cuda()\n",
    "    prev_b = prev_b.cuda()\n",
    "\n",
    "real_a = Variable(real_a)\n",
    "real_b = Variable(real_b)\n",
    "prev_b = Variable(prev_b)\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        # forward\n",
    "        real_a_cpu, real_b_cpu, prev_b_cpu = batch[0], batch[1], batch[2]\n",
    "        real_a.data.resize_(real_a_cpu.size()).copy_(real_a_cpu)\n",
    "        real_b.data.resize_(real_b_cpu.size()).copy_(real_b_cpu)\n",
    "        prev_b.data.resize_(prev_b_cpu.size()).copy_(prev_b_cpu)\n",
    "\n",
    "        input_joined = torch.cat((real_a,prev_b),1)\n",
    "\n",
    "        fake_b = netG(input_joined)\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # train with fake\n",
    "        fake_ab = torch.cat((real_a, prev_b, fake_b), 1)\n",
    "        pred_fake = netD.forward(fake_ab.detach())\n",
    "        loss_d_fake = criterionGAN(pred_fake,False,True)\n",
    "\n",
    "        # train with real\n",
    "        real_ab = torch.cat((real_a, prev_b, real_b), 1)\n",
    "        pred_real = netD.forward(real_ab)\n",
    "        loss_d_real = criterionGAN(pred_real, True, True) \n",
    "\n",
    "\n",
    "        # Combined loss\n",
    "        loss_d = (loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "        loss_d.backward()\n",
    "\n",
    "        #Discriminator parameters update every 12 iterations \n",
    "        if (iteration == 1 or iteration % 12 == 0):\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))\n",
    "        ##########################\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        # First, G(A) should fake the discriminator\n",
    "        fake_ab = torch.cat((real_a, prev_b,fake_b), 1)\n",
    "        pred_fake = netD.forward(fake_ab)\n",
    "        loss_g_gan = criterionGAN(pred_fake, True, False)\n",
    "\n",
    "        # Second, G(A) = B\n",
    "        loss_g_l1 = criterionL1(fake_b, real_b) * opt.L1lamb\n",
    "        loss_g = loss_g_gan + loss_g_l1\n",
    "\n",
    "        loss_g_style = criterionSTYLE(fake_b,real_b) * opt.Stylelamb\n",
    "        loss_g = loss_g + loss_g_style\n",
    "\n",
    "        loss_g_content = criterionCONTENT(fake_b,real_b) * opt.Contentlamb\n",
    "        loss_g = loss_g + loss_g_content\n",
    "\n",
    "        loss_g.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        if (iteration % 25 == 0):\n",
    "            logs = [(\"epoc\", epoch),(\"iter\", iteration),(\"Loss_G\", loss_g.item()),(\"Loss_D\", loss_d.item()), (\"Loss_G_adv\",loss_g_gan.item()),(\"Loss_G_L1\",loss_g_l1.item()),(\"Loss_G_style\",loss_g_style.item()),(\"Loss_G_content\",loss_g_content.item()),(\"Loss_D_Real\",loss_d_real.item()),(\"Loss_D_Fake\",loss_d_fake.item())]\n",
    "            log_train_data(logs)\n",
    "\n",
    "        if(iteration % 250 == 0):\n",
    "            sample(iteration)\n",
    "\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f} LossD_Fake: {:.4f} LossD_Real: {:.4f}  LossG_Adv: {:.4f} LossG_L1: {:.4f} LossG_Style {:.4f} LossG_Content {:.4f}\".format(\n",
    "           epoch, iteration, len(training_data_loader), loss_d, loss_g, loss_d_fake, loss_d_real, loss_g_gan, loss_g_l1, loss_g_style, loss_g_content))\n",
    "\n",
    "def sample(iteration):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        input,target,prev_frame = next(sample_iterator)\n",
    "        \n",
    "        if opt.cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            prev_frame = prev_frame.cuda()\n",
    "\n",
    "        pred_input = torch.cat((input,prev_frame),1)\n",
    "        prediction = netG(pred_input)\n",
    "        prediction = postprocess(prediction)\n",
    "        input = postprocess(input)\n",
    "        target = postprocess(target)\n",
    "\n",
    "    img = stitch_images(input, target, prediction)\n",
    "    samples_dir = root_path + \"/samples\"\n",
    "\n",
    "    if not os.path.exists(samples_dir):\n",
    "        os.makedirs(samples_dir)\n",
    "\n",
    "    sample = opt.dataset + \"_\" + str(epoch) + \"_\" + str(iteration).zfill(5) + \".png\"\n",
    "    print('\\nsaving sample ' + sample + ' - learning rate: ' + str(opt.lr))\n",
    "    img.save(os.path.join(samples_dir, sample))\n",
    "\n",
    "def log_train_data(loginfo):\n",
    "    log_dir = root_path + \"/logs\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    log_file = log_dir + \"/\" + opt.logfile\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write('%s\\n' % ' '.join([str(item[1]) for item in loginfo]))\n",
    "\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    if not os.path.exists(\"checkpoint\"):\n",
    "        os.mkdir(\"checkpoint\")\n",
    "    if not os.path.exists(os.path.join(\"checkpoint\", opt.dataset)):\n",
    "        os.mkdir(os.path.join(\"checkpoint\", opt.dataset))\n",
    "    net_g_model_out_path = \"checkpoint/{}/netG_weights_epoch_{}.pth\".format(opt.dataset, epoch)\n",
    "    net_d_model_out_path = \"checkpoint/{}/netD_weights_epoch_{}.pth\".format(opt.dataset, epoch)\n",
    "    \n",
    "    torch.save({'generator': netG.state_dict()}, net_g_model_out_path)\n",
    "    torch.save({'discriminator': netD.state_dict()}, net_d_model_out_path)\n",
    "    \n",
    "    print(\"Checkpoint saved to {}\".format(\"checkpoint\" + opt.dataset))\n",
    "\n",
    "for epoch in range(1, opt.nEpochs + 1):\n",
    "    train(epoch)\n",
    "    checkpoint(epoch)\n",
    "\n",
    "\n",
    "def run():\n",
    "    torch.multiprocessing.freeze_support()\n",
    "    print('loop')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Loss And Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.cuda and not torch.cuda.is_available():\n",
    "    raise Exception(\"No GPU found, please run without --cuda\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(opt.seed)\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed(opt.seed)\n",
    "\n",
    "print('===> Loading datasets')\n",
    "root_path = opt.root\n",
    "train_set = get_training_set(join(root_path , opt.dataset))\n",
    "test_set = get_test_set(join(root_path , opt.dataset))\n",
    "\n",
    "training_data_loader = DataLoader(dataset=train_set, num_workers=opt.threads, batch_size=opt.batchSize, shuffle=True)\n",
    "testing_data_loader = DataLoader(dataset=test_set, num_workers=opt.threads, batch_size=opt.testBatchSize, shuffle=False)\n",
    "\n",
    "sample_iterator = create_iterator(6, test_set)\n",
    "\n",
    "netG = define_G(opt.input_nc, opt.output_nc, opt.ngf, False, [0])\n",
    "netD = define_D(opt.input_nc + opt.output_nc, opt.ndf, False, [0])\n",
    "\n",
    "if opt.checkpoint_path_G and opt.checkpoint_path_D:\n",
    "    load(opt.checkpoint_path_G, opt.checkpoint_path_D, netG, netD)\n",
    "\n",
    "criterionGAN = AdversarialLoss()\n",
    "criterionSTYLE = StyleLoss()\n",
    "criterionCONTENT = PerceptualLoss()\n",
    "criterionL1 = nn.L1Loss()\n",
    "criterionMSE = nn.MSELoss()\n",
    "\n",
    "# setup optimizer\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr * 0.1, betas=(opt.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_a = torch.FloatTensor(opt.batchSize, opt.input_nc, 256, 256)\n",
    "real_b = torch.FloatTensor(opt.batchSize, opt.output_nc, 256, 256)\n",
    "prev_b = torch.FloatTensor(opt.batchSize, opt.output_nc, 256, 256)\n",
    "\n",
    "if opt.cuda:\n",
    "    netD = netD.cuda()\n",
    "    netG = netG.cuda()\n",
    "    criterionGAN = criterionGAN.cuda()\n",
    "    criterionL1 = criterionL1.cuda()\n",
    "    critertionSTYLE = criterionSTYLE.cuda()\n",
    "    criterionCONTENT = criterionCONTENT.cuda()\n",
    "    criterionMSE = criterionMSE.cuda()\n",
    "    real_a = real_a.cuda()\n",
    "    real_b = real_b.cuda()\n",
    "    prev_b = prev_b.cuda()\n",
    "\n",
    "real_a = Variable(real_a)\n",
    "real_b = Variable(real_b)\n",
    "prev_b = Variable(prev_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "\n",
    "    for iteration, batch in enumerate(training_data_loader, 1):\n",
    "        # forward\n",
    "        real_a_cpu, real_b_cpu, prev_b_cpu = batch[0], batch[1], batch[2]\n",
    "        real_a.data.resize_(real_a_cpu.size()).copy_(real_a_cpu)\n",
    "        real_b.data.resize_(real_b_cpu.size()).copy_(real_b_cpu)\n",
    "        prev_b.data.resize_(prev_b_cpu.size()).copy_(prev_b_cpu)\n",
    "\n",
    "        input_joined = torch.cat((real_a,prev_b),1)\n",
    "\n",
    "        fake_b = netG(input_joined)\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x,y)) + log(1 - D(x,G(x)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # train with fake\n",
    "        fake_ab = torch.cat((real_a, prev_b, fake_b), 1)\n",
    "        pred_fake = netD.forward(fake_ab.detach())\n",
    "        loss_d_fake = criterionGAN(pred_fake,False,True)\n",
    "\n",
    "        # train with real\n",
    "        real_ab = torch.cat((real_a, prev_b, real_b), 1)\n",
    "        pred_real = netD.forward(real_ab)\n",
    "        loss_d_real = criterionGAN(pred_real, True, True) \n",
    "\n",
    "\n",
    "        # Combined loss\n",
    "        loss_d = (loss_d_fake + loss_d_real) * 0.5\n",
    "\n",
    "        loss_d.backward()\n",
    "\n",
    "        #Discriminator parameters update every 12 iterations \n",
    "        if (iteration == 1 or iteration % 12 == 0):\n",
    "            optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(x,G(x))) + L1(y,G(x))\n",
    "        ##########################\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        # First, G(A) should fake the discriminator\n",
    "        fake_ab = torch.cat((real_a, prev_b,fake_b), 1)\n",
    "        pred_fake = netD.forward(fake_ab)\n",
    "        loss_g_gan = criterionGAN(pred_fake, True, False)\n",
    "\n",
    "        # Second, G(A) = B\n",
    "        loss_g_l1 = criterionL1(fake_b, real_b) * opt.L1lamb\n",
    "        loss_g = loss_g_gan + loss_g_l1\n",
    "\n",
    "        loss_g_style = criterionSTYLE(fake_b,real_b) * opt.Stylelamb\n",
    "        loss_g = loss_g + loss_g_style\n",
    "\n",
    "        loss_g_content = criterionCONTENT(fake_b,real_b) * opt.Contentlamb\n",
    "        loss_g = loss_g + loss_g_content\n",
    "\n",
    "        loss_g.backward()\n",
    "\n",
    "        optimizerG.step()\n",
    "\n",
    "        if (iteration % 25 == 0):\n",
    "            logs = [(\"epoc\", epoch),(\"iter\", iteration),(\"Loss_G\", loss_g.item()),(\"Loss_D\", loss_d.item()), (\"Loss_G_adv\",loss_g_gan.item()),(\"Loss_G_L1\",loss_g_l1.item()),(\"Loss_G_style\",loss_g_style.item()),(\"Loss_G_content\",loss_g_content.item()),(\"Loss_D_Real\",loss_d_real.item()),(\"Loss_D_Fake\",loss_d_fake.item())]\n",
    "            log_train_data(logs)\n",
    "\n",
    "        if(iteration % 250 == 0):\n",
    "            sample(iteration)\n",
    "\n",
    "\n",
    "        print(\"===> Epoch[{}]({}/{}): Loss_D: {:.4f} Loss_G: {:.4f} LossD_Fake: {:.4f} LossD_Real: {:.4f}  LossG_Adv: {:.4f} LossG_L1: {:.4f} LossG_Style {:.4f} LossG_Content {:.4f}\".format(\n",
    "           epoch, iteration, len(training_data_loader), loss_d, loss_g, loss_d_fake, loss_d_real, loss_g_gan, loss_g_l1, loss_g_style, loss_g_content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, opt.nEpochs + 1):\n",
    "    train(epoch)\n",
    "    checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing settings\n",
    "opt = {\n",
    "    'root': './',\n",
    "    'dataset': 'frames/',\n",
    "    'model': 'checkpoint/facades/netG_model_epoch_200.pth',\n",
    "    'cuda':'store_true'\n",
    "}\n",
    "\n",
    "root_path = opt.root\n",
    "val_set = get_val_set(os.path.join(root_path , opt.dataset))\n",
    "\n",
    "seq_sampler = SequentialSampler(val_set)\n",
    "\n",
    "val_data_loader = DataLoader(dataset=val_set, num_workers=0, batch_size=1, shuffle=False,sampler = seq_sampler)\n",
    "\n",
    "checkpoint = torch.load(opt.model)\n",
    "netG = InpaintGenerator()\n",
    "netG.load_state_dict(checkpoint['generator'])\n",
    "netG.cuda()\n",
    "\n",
    "transform_list = [transforms.ToTensor(),\n",
    "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "\n",
    "transform = transforms.Compose(transform_list)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_data_loader:\n",
    "        input, target, prev_frame = Variable(batch[0], volatile=True), Variable(batch[1], volatile=True), Variable(batch[2], volatile=True)\n",
    "        if opt.cuda:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "            prev_frame = prev_frame.cuda()\n",
    "        if counter != 0:\n",
    "            prev_frame = tmp\n",
    "            print(\"success\")\n",
    "        pred_input = torch.cat((input,prev_frame),1)\n",
    "        out = netG(pred_input)\n",
    "        tmp = out\n",
    "        \n",
    "        if not os.path.exists(os.path.join(\"results\", opt.dataset)):\n",
    "            os.makedirs(os.path.join(\"results\", opt.dataset))\n",
    "       \n",
    "        image_name = opt.dataset + \"_\" + str(counter).zfill(5) + \".jpg\"\n",
    "        save_image(out,\"results/{}/{}\".format(opt.dataset, image_name))\n",
    "        print(\"saving:\"+image_name)\n",
    "        \n",
    "        counter += 1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3_Question3_Bonus.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
